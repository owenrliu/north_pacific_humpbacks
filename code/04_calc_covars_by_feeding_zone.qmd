---
title: "Calculate Environmental Covariates"
format: html
toc: true
toc_float: true
toc-title: "Navigation"
embed-resources: true
editor: source
---

## Purpose

Using the modeled data from GLORYS, build environmental covariates to test in the assessment model. This will take advantage of the steps we've already completed when we downloaded the ocean data (`01_download_GLORYS.R`), and defined the zones over which to calculate these metrics (`define spatial zones.qmd`)

```{r setup}
library(ncdf4) 
library(tidync)
library(sf)
library(terra)
library(tidyverse)
library(tidyterra)
library(viridis)
library(cowplot)
library(here)
library(tictoc) # for timing code

theme_set(theme_classic())
```

## Setup

Load the polygons/humpback zones.

```{r}
zones <- read_sf(here('data','spatial','NPhump_zones_scenarios.shp'))
zones_bbs <- map(zones$geometry,st_bbox)
fzones <- zones %>% filter(Feeding) # feeding zones only

# make a vect() version for terra package
fzonesv <- vect(fzones)

zones %>% 
  ggplot()+
  geom_sf(aes(fill=Feeding))+labs(fill="Feeding\nGround")
```

## Extract and Mask

To derive time series, we will use raster extractions from the GLORYS netCDFs. In a previous script, `define spatial zones.qmd`, we used spatial analyses to define a raster mask for "shelf habitat" for both the physics and biogeochemical model outputs from GLORYS, corresponding to GLORYS model grid cells that are 1) within the polygons mapped above, and 2) are less than 1000m deep. We will use these rasters to mask/crop the spatial data from the netCDFs, and then we can calculate summary statistics for particular months or years from those cropped rasters. Let's write some functions to help us do that.

### Raster masks

Here are the raster masks for the two GLORYS datasets (remember, the reason they are different is because the GLORYS BGC is on a 0.25deg grid, while the physics is on a 1/12deg (0.083) grid)

```{r}
mask1k_bgc <- rast(here('data','spatial','GLORYS_bgc_1000m_mask.tif'))
mask1k_phys<- rast(here('data','spatial','GLORYS_phys_1000m_mask.tif'))

plot(mask1k_bgc,main="Biogeochemistry 1000m mask")
plot(mask1k_phys,main="Physics 1000m mask")

```

Create a quick file lookup table so we can easily access the right file for a given variable, year, and zone. For now, we are only concerned about calculating summaries for the feeding grounds/feeding zones.

```{r}
# this populates all the combinations of years, months, zones, and datasets
fls_tbl <- crossing(year=1993:2024, 
                    month=1:12,
                    zoneID=unique(fzones$zoneID), # feeding zones
                    dataset=c("phys","bgc")) %>% 
  mutate(fn=case_when(
    # point to the correct file locations.
    dataset=="phys" & year %in% c(1993:2020) ~ paste0("data/glorys/phys/raw/glorys_physics_",zoneID,"_1993-2021.nc"),
    dataset=="phys" & year %in% c(2022:2024) ~ paste0("data/glorys/phys/raw/glorys_physics_",zoneID,"_2021-2024.nc"),
    dataset=="phys" & year==2021 & month %in% c(1:6) ~ paste0("data/glorys/phys/raw/glorys_physics_",zoneID,"_1993-2021.nc"),
    dataset=="phys" & year==2021 & month %in% c(7:12) ~ paste0("data/glorys/phys/raw/glorys_physics_",zoneID,"_2021-2024.nc"),
    
    dataset=="bgc" & year %in% c(1993:2022) ~ paste0("data/glorys/bgc/raw/glorys_bgc_",zoneID,"_1993-2022.nc"),
    dataset=="bgc" & year %in% c(2023:2024) ~ paste0("data/glorys/bgc/raw/glorys_bgc_",zoneID,"_2023-2024.nc"),
  ))
```

### Extract function

Now write the extraction function

```{r}
# extract the appropriate data for a chosen variable, year, month, and zone
# as of 07/21/25, the variables we have downloaded include:
# for physics: thetao (i.e., temperature, in this case SST), mlotst (i.e., mixed layer depth)
# for biogeochemistry: chl (chlorophyll), no3 (nitrate), nppv (primary production as measured in carbon)

extr_yr_mth_zone <- function(v,y,m,z){
  
  # find the dataset type
  if(!(v%in%c('thetao','mlotst','chl','no3','nppv'))) stop("variable must be one of c('thetao','mlotst','chl','no3','nppv')")
  type <- ifelse(v %in% c('thetao','mlotst'),"phys","bgc")
  
  # load the correct raster mask
  if(type=="phys") rmask <- mask1k_phys
  if(type=="bgc") rmask <- mask1k_bgc
  
  # find the right nc file to load using the files table we made above
  fn <- fls_tbl %>% filter(year==y,month==m,dataset==type,zoneID==z) %>% pull(fn)
  
  # time slice we want
  t <- as.Date(paste(y,m,"01",sep="-"))
  
  # now, finally we can load the data
  datr <- rast(here(fn),subds=v) # raster for the right zone and variable
  datr <- datr[[time(datr)==t]] # subset the raster for the right year/month
  rext <- ext(datr) %>% as.vector() # extent/bounding box of the raster
  if(any(rext<0)) datr <- rotate(datr) # convert from [-180,180] to [0,360] if needed
  rmaskcrop <- crop(rmask,datr) # crop the raster mask to the extent of the data
  
  # use the mask to set NA for unwanted cells (>1000m deep) in the data raster
  datr <- mask(datr,rmaskcrop)
  
  # trim the final raster using the zone polygon to set NA for cells not covered by the polygon 
  zv <- fzonesv %>% subset(fzonesv$zoneID==z)
  outr <- datr %>% mask(zv)
  
  return(outr)
}
```


Test this

```{r}
# for a physical variable
# arbitrary- mixed layer depth in january 2022 for the Eastern Aleutians and Bering Sea
mldj2022 <- extr_yr_mth_zone("mlotst",2022,1,"EAL+BER_16")
plot(mldj2022,main="MLD January 2022")

# arbitrary- net primary productivity in september 1995 for the same region
nppvsep2022 <- extr_yr_mth_zone("nppv",1995,9,"EAL+BER_16")
plot(nppvsep2022,main="NPPV September 1995")

# this is fast! and seems to work well
```

We can use this extraction function as a building block for calculating environmental time series, by summarizing long term climatologies and anomalies over certain years/months.

## Summary function

With the ability to extract the environmental data for the correct zone and month combinations, the last thing we need is a function to perform some general summaries across multiple layers/time slices of those extractions.

This summary function extracts the data for a given variable, ranges of years/months, and zone. Then it stacks those data slices into a multilayer raster (or raster brick), and performs a specified function `fun` on that stack using `terra::app()`. We can use the function for, e.g., calculating the mean sst field in particular zones and across specific years. The `app()` function applies to the values of each cell of the raster, across layers/time. In other words, `app(rast,"mean")` would return a single-layer raster, whose cell values are equal to the mean in each cell across time.

```{r}
calc_summary_r <- function(v,year_start,year_end,month_start,month_end,z,fun="mean"){
  
  # find all the rasters to extract
  year_range <- year_start:year_end
  month_range <- month_start:month_end
  slices <- crossing(y=year_range,m=month_range)
  
  # extract the data then combine into a stack
  rb <- map2(slices$y,slices$m,\(y,m) extr_yr_mth_zone(v,y,m,z)) %>% rast()
  
  # apply a function across the stack
  outr <- app(rb,fun)
  
  return(outr)
}
```

## Tests

Try out and explore these functions. First (somewhat arbitrarily) let's explore August SST in the northern Gulf of Alaska. Here we use the functions to calculate a few different versions of SST.

### Gulf of Alaska SST

August mean SST, 1993:2013, Northern Gulf of Alaska.

```{r}
ngoa_mean_sst <- calc_summary_r(v="thetao",year_start=1993,year_end=2013,month_start=8,month_end=8,z="NGOA_8")

x1 <- ggplot()+
  geom_spatraster(data=ngoa_mean_sst)+
  geom_sf(data=zones %>% filter(Name=="NGOA"),fill=NA)+
  labs(title="NGOA Mean August SST, 1993 to 2013")+
  scale_fill_viridis(option='turbo',na.value=NA,limits=c(10,16))
```

90th quantile August temperature for the same region.

```{r}
# 90th quantile August temperature for the same region
ngoa_sst90 <- calc_summary_r(v="thetao",year_start=1993,year_end=2013,month_start=8,month_end=8,z="NGOA_8",
                                fun = \(x) quantile(x,0.9,na.rm=T))
x2 <- ggplot()+
  geom_spatraster(data=ngoa_sst90)+
  geom_sf(data=zones %>% filter(Name=="NGOA"),fill=NA)+
  labs(title="NGOA 90th quantile August SST, 1993 to 2013")+
  scale_fill_viridis(option='turbo',na.value=NA,limits=c(10,16))
```

2016 August temperature for the same region.
```{r}
# 2016 August temperature for the same region
ngoa_aug2016 <- extr_yr_mth_zone('thetao',2016,8,"NGOA_8")
x3 <- ggplot()+
  geom_spatraster(data=ngoa_aug2016)+
  geom_sf(data=zones %>% filter(Name=="NGOA"),fill=NA)+
  labs(title="NGOA August SST, 2016")+
  scale_fill_viridis(option='turbo',na.value=NA,limits=c(10,16))
```

Finally, anomaly relative to 1993:2013 mean. we can just substract the rasters

```{r}
# anomaly relative to 1993:2013 mean. we can just substract the rasters
ngoa_anom2016 <- ngoa_aug2016-ngoa_mean_sst
x4 <- ggplot()+
  geom_spatraster(data=ngoa_anom2016)+
  geom_sf(data=zones %>% filter(Name=="NGOA"),fill=NA)+
  labs(title="NGOA August SST anomaly, 2016")+
  scale_fill_viridis(option='D',na.value=NA)

plot_grid(x1,x2,x3,x4,nrow=2)
```

### Western Aleutians NPPV

Next, net primary production (carbon/m3/day) at the surface in the Russia and Western Aleutians zone.

```{r}
# August mean nppv, 1993:2013, Russia and Western Aleutians
wal_mean_nppv <- calc_summary_r(v="nppv",year_start=1993,year_end=2013,month_start=8,month_end=8,z="RUS+WAL_15")
ggplot()+
  geom_spatraster(data=wal_mean_nppv)+
  geom_sf(data=zones %>% filter(zoneID=="RUS+WAL_15"),fill=NA)+
  scale_fill_viridis(option='D',na.value=NA)
```

Try to construct an anomaly time series from this, using the mean raster we just created. We do this by

* subtracting the mean SST raster from each year/month raster layer to create a stack of anomaly rasters
* summarizing the mean and SD of each of these rasters (across cells) to create the time series.

```{r}
# August anomaly from 1993:2013 baseline
wal_aug_nppv <- calc_summary_r(v="nppv",year_start = 1993,year_end=2024,month_start = 8,month_end = 8,z="RUS+WAL_15",fun=\(x) x)
wal_anom_nppv <- wal_aug_nppv-wal_mean_nppv

# in map form
plot(wal_anom_nppv[[1:6]])

# collapsed to a time series
wal_nppv_ts <- tibble(year=1993:2024,
                      anom=lapply(wal_anom_nppv,\(x)mean(values(x),na.rm=T)),
                      sd=lapply(wal_anom_nppv,\(x) sd(values(x),na.rm=T))) %>% 
  mutate(across(where(is.list),as.numeric))
p4<-wal_nppv_ts %>% 
  ggplot(aes(year,anom))+
  geom_point()+geom_line()

# what about as a difference in total (sum) nppv?
wal_aug_sum_nppv <- sum(values(wal_mean_nppv),na.rm=T)
wal_sum_anom_nppv <- lapply(wal_aug_nppv,\(x) sum(values(x),na.rm=T)-wal_aug_sum_nppv) %>% as.numeric()

p5<-tibble(year=1993:2024,sumanom=wal_sum_anom_nppv) %>% 
  ggplot(aes(year,sumanom))+
  geom_point()+
  geom_line()
p4;p5 # these are functionally identical, which makes sense: p5 is p4*ncells
```

### April mixed layer depth in southern BC and Washington.

```{r}
# mean mld, 1993 to 2013
sbc_mean_mld <- calc_summary_r(v="mlotst",year_start=1993,year_end=2013,month_start=4,month_end=4,z="SBC+WA_11")

x1 <- ggplot()+
  geom_spatraster(data=sbc_mean_mld)+
  geom_sf(data=zones %>% filter(Name=="SBC+WA"),fill=NA)+
  labs(title="SBC Mean April mixed layer depth, 1993 to 2013")+
  scale_fill_viridis(option='D',na.value=NA,direction = -1,limits=c(5,20))

# 2016 April mld for the same region
sbc_apr2016 <- extr_yr_mth_zone('mlotst',2016,8,"SBC+WA_11")
x2 <- ggplot()+
  geom_spatraster(data=sbc_apr2016)+
  geom_sf(data=zones %>% filter(Name=="SBC_WA"),fill=NA)+
  labs(title="SBC April mixed layer depth, 2016")+
  scale_fill_viridis(option='D',na.value=NA,direction = -1,limits=c(5,20))

# anomaly relative to 1993:2013 mean. we can just substract the rasters
sbc_anom2016 <- sbc_apr2016-sbc_mean_mld
x3 <- ggplot()+
  geom_spatraster(data=sbc_anom2016)+
  geom_sf(data=zones %>% filter(Name=="SBC+WA"),fill=NA)+
  labs(title="SBC April mixed layer depth anomaly, 2016")+
  scale_fill_viridis(option='D',na.value=NA)

cowplot::plot_grid(x1,x2,x3,nrow=2)
```

## Anomaly timeseries

Calculate anomaly time series for all feeding grounds. We write another wrapper function that returns an anomaly time series for a given zone and variable, and a chosen baseline period.

```{r}
calc_anom_ts <- function(v,year_start,year_end,baseline_start,baseline_end,month_start,month_end,z,baseline_fun='mean'){
  # baseline raster with function applied
  baser <- calc_summary_r(v,baseline_start,baseline_end,month_start,month_end,z,baseline_fun)
  
  # time series of anomalies from the baseline
  # WARNING: this assumes baseline_fun produced a raster that makes sense when subtracted from the raw values in these rasters (e.g., a mean)
  rts <- calc_summary_r(v,year_start,year_end,month_start,month_end,z,fun=\(x) x)
  
  # difference (anomaly) stack
  anomr <- rts-baser
  
  # collapse to time series
  out <- crossing(year=year_start:year_end,
                  month=month_start:month_end) %>% 
    mutate(anom=lapply(anomr,\(x) mean(values(x),na.rm=T)),
           sd=lapply(anomr,\(x) sd(values(x),na.rm=T))) %>%
    mutate(across(where(is.list),as.numeric)) %>% 
    group_by(year) %>% 
    summarise(anom=mean(anom),sd=mean(sd)) %>% 
    ungroup()
  
  return(out)
}
```

### Gulf of Alaska SST and chlorophyll

Let's look at the same NGOA SST from before, as a time series based on different baselines.

```{r}
# Baseline 1993:2003
ngoa_sst_ts1 <- calc_anom_ts(v="thetao",year_start=1993,year_end=2024,baseline_start = 1993,baseline_end = 2003,month_start=6,month_end=9,z="NGOA_8",baseline_fun='mean')

ngoa_sst_ts1_p <- ngoa_sst_ts1 %>% 
  ggplot(aes(year,anom,ymax=anom+sd,ymin=anom-sd))+
  geom_ribbon(fill='lightblue')+
  geom_line()+
  geom_hline(yintercept=0,linetype=2)+
  labs(title="SST anomaly, NGOA\n1993 to 2003 baseline")

# Baseline 1993:2013
ngoa_sst_ts2 <- calc_anom_ts(v="thetao",year_start=1993,year_end=2024,baseline_start = 1993,baseline_end = 2013,month_start=6,month_end=9,z="NGOA_8",baseline_fun='mean')

ngoa_sst_ts2_p <- ngoa_sst_ts2 %>% 
  ggplot(aes(year,anom,ymax=anom+sd,ymin=anom-sd))+
  geom_ribbon(fill='lightblue')+
  geom_line()+
  geom_hline(yintercept=0,linetype=2)+
  labs(title="SST anomaly, NGOA\n1993 to 2013 baseline")

ngoa_sst_ts1_p
ngoa_sst_ts2_p
```


```{r}
ngoa_chl_ts <- calc_anom_ts(v="chl",year_start=1993,year_end=2024,baseline_start = 1993,baseline_end = 2013,month_start=6,month_end=9,z="NGOA_8",baseline_fun='mean')

ngoa_chl_ts_p <- ngoa_chl_ts %>% 
  ggplot(aes(year,anom,ymax=anom+sd,ymin=anom-sd))+
  geom_ribbon(fill='lightblue')+
  geom_line()+
  geom_hline(yintercept=0,linetype=2)+
  labs(title="chl anomaly, NGOA\n1993 to 2013 baseline")

ngoa_chl_ts_p
```

### All Regions

Produce time series like this for temperature and chlorophyll for all feeding zones. Now using June to August, with a baseline of 1993-2013.

```{r}
sst_anoms <- map(fzones$zoneID,function(zone) {
  calc_anom_ts(v="thetao",year_start=1993,year_end=2024,baseline_start = 1993,baseline_end = 2013,month_start=6,month_end=8,z=zone,baseline_fun='mean') %>% mutate(zoneID=zone)
}) %>% bind_rows()

all_sst_p <- sst_anoms %>% 
  ggplot(aes(year,anom,ymax=anom+sd,ymin=anom-sd))+
  geom_ribbon(fill='lightblue')+
  geom_line()+
  geom_vline(xintercept=2015,linetype=2)+
  geom_hline(yintercept=0,linetype=2)+
  facet_wrap(~zoneID)+
  labs(title="SST summer anomaly, 1993 to 2013 baseline")
all_sst_p
```

Now for chlorophyll.

```{r}
chl_anoms <- map(fzones$zoneID,function(zone) {
  calc_anom_ts(v="chl",year_start=1993,year_end=2024,baseline_start = 1993,baseline_end = 2013,month_start=6,month_end=8,z=zone,baseline_fun='mean') %>% mutate(zoneID=zone)
}) %>% bind_rows()

all_chl_p <- chl_anoms %>% 
  ggplot(aes(year,anom,ymax=anom+sd,ymin=anom-sd))+
  geom_ribbon(fill='lightblue')+
  geom_line()+
  geom_vline(xintercept=2015,linetype=2)+
  geom_hline(yintercept=0,linetype=2)+
  facet_wrap(~zoneID)+
  labs(title="chl summer anomaly, 1993 to 2013 baseline")
all_chl_p
```

